{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COO Assessment - Question 3\n",
    "\n",
    "- We are given the Prisoner's Dilemma as a Bargaining Problem\n",
    "- The Prisoners’ Dilemma is a famous model for illustrating the conflict between social cooperation and self-interested behavior.\n",
    "- We first import the necessary packages needed for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import *\n",
    "from math import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consider a two player Prisoners’ Dilemma.\n",
    "- The cooperative payoff possibilities are mathematically described by a polytope which is defined\n",
    "as the convex hull of the payoff vectors (4,4), (6,0), (0,6) and (0,0).\n",
    "- We plot this convex hull for the problem below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We are going to model the Prisoner's Dilemma game using CVXPY\n",
    "# The game is played between two players, A and B\n",
    "# We are given that cooperative payoff possibilities are mathematically described by a polytope which is defined as the convex hull of the payoff vectors (4,4), (6,0), (0,6) and (0,0).\n",
    "\n",
    "# Define the payoff vectors\n",
    "payoff_vectors = np.array([[4,4],[6,0],[0,6],[0,0]])\n",
    "\n",
    "# Define the convex hull of the payoff vectors\n",
    "convex_hull = np.array([[0,0],[0,6],[4,4],[6,0]])\n",
    "\n",
    "# Plot the payoff vectors and the convex hull\n",
    "plt.plot(payoff_vectors[:,0], payoff_vectors[:,1], 'o')\n",
    "plt.plot(convex_hull[:,0], convex_hull[:,1], 'r-')\n",
    "plt.xlabel('Player A payoff')\n",
    "plt.ylabel('Player B payoff')\n",
    "plt.title('Convex Hull of the Payoff Vectors')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We think of the Prisoner's Dilemma as a Bargaining situation with the disagreement point as $d = (d_1, d_2)$\n",
    "\n",
    "- The notion of a disagreement point introduces a constraint that player $i$ cannot get a payoff below her disagreement point payoff $d_i$\n",
    "\n",
    "- Upon modelling this situation given to us, we are presented with the following constraints:\n",
    "$$\n",
    "u_1 + 2u_2 \\leq 12\n",
    "$$\n",
    "$$\n",
    "u_2 + 2u_1 \\leq 12\n",
    "$$\n",
    "$$\n",
    "u_1 \\geq d_1\n",
    "$$\n",
    "$$\n",
    "u_2 \\geq d_2\n",
    "$$\n",
    "\n",
    "- where $(u_1, u_2)$ is the payoff vectors for the two players in the bargaining situation.\n",
    "- The constraints given above define the feasible set ($F$) for our constrained optimisation problem which we are going to solve in the forthcoming questions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "\n",
    "- In this question, keeping the feasible set the same we need to maximise the Nash Welfare Criterion defined as:\n",
    "$$\n",
    "N(u_1, u_2) = \\log(u_1-d_1) + \\log(u_2-d_2) \n",
    "$$\n",
    "\n",
    "- The Nash Bargaining Solution of the Bargaining Problem (i.e. our Objective Function) is given by:\n",
    "$$\n",
    "\\max_{(u_1, u_2)} N(u_1, u_2)\n",
    "$$\n",
    "$$\n",
    "such \\space that \\space (u_1, u_2) \\in F\n",
    "$$\n",
    "\n",
    "- The disagreement point given to us is:\n",
    "$$\n",
    "(d_1, d_2) = (2, 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the disagreement point given to us\n",
    "d = np.array([2, 1])\n",
    "d1 = d[0]\n",
    "d2 = d[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We define the constraints for our problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the constraints for the problem\n",
    "def constraint1(u):\n",
    "    u1 = u[0]\n",
    "    u2 = u[1]\n",
    "    return 12 - u1 - 2*u2 \n",
    "\n",
    "def constraint2(u):\n",
    "    u1 = u[0]\n",
    "    u2 = u[1]\n",
    "    return 12 - 2*u1 - u2 \n",
    "\n",
    "def constraint3(u):\n",
    "    u1 = u[0]\n",
    "    return u1 - d1\n",
    "\n",
    "def constraint4(u):\n",
    "    u2 = u[1]\n",
    "    return u2 - d2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Barrier Technique\n",
    "\n",
    "- Since we are not allowed to use the CVXPY library, we implement the Interior Point Algorithm in this problem to solve our inequality constrained convex optimisation problem described.\n",
    "\n",
    "- The Interior Point Algorithm uses the Log Barrier Method to handle the inequalities.\n",
    "\n",
    "- The Function with the inequalities is written as (where m is the number of inequality constraints):\n",
    "$$\n",
    "B(x) = \\sum_{i=1}^{m} (-(\\log(-f_{i}(x))))\n",
    "$$\n",
    "- where $f_{i}(x) \\leq 0$\n",
    "\n",
    "- If our objective function is defined as $f_{0}(x)$, our combined objective function without any constraints becomes:\n",
    "$$\n",
    "\\phi(x) = t*f_{0}(x) + B(x) \n",
    "$$\n",
    "\n",
    "- In our case, the log barrier function $B(x)$ is equal to:\n",
    "$$\n",
    "B(u_1, u_2) = -[\\log(-(2u_2 + u_1 - 12)) + \\log(-(2u_1 + u_2 - 12)) + \\log(-(d_1 - u_1)) + \\log(-(d_2 - u_2))]\n",
    "$$\n",
    "\n",
    "- Since we use Newton Descent for finding the minimum of a unconstrained function and we find to maximise the Nash Welfare Criterion, we simply minimise its negative. Therefore our objective function becomes:\n",
    "$$\n",
    "\\min_{(u_1, u_2)} \\space -\\log(u_1 - d_1) - \\log(u_2 - d_2)\n",
    "$$\n",
    "\n",
    "- Thus, $f_{0}(u_1, u_2)$ is equal to $-\\log(u_1 - d_1) - \\log(u_2 - d_2)$\n",
    "\n",
    "- Hence our final unconstrained minimisation problem $N(u_1, u_2)$ is:\n",
    "$$\n",
    "\\min_{(u_1, u_2)} \\space t*f_{0}(u_1, u_2) + B(u_1, u_2)\n",
    "$$\n",
    "\n",
    "- We first define this as a function in our code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the objective function with the inequality constraints handled using the log barrier function\n",
    "def Nash(u, t):\n",
    "    u1 = u[0]\n",
    "    u2 = u[1]\n",
    "\n",
    "    # Try except done to handle negative infinity penalty of the log barrier function\n",
    "    try:\n",
    "        return -(np.log((12-2*u2-u1)*(12-2*u1-u2)*(u1-d1)*(u2-d2))/t) - np.log((u1-d1)*(u2-d2))\n",
    "    except:\n",
    "        return -1e-20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the gradient, we need expressions for the partial derivates of $N(u_1, u_2)$ wrt $u_1$ and $u_2$:\n",
    "$$\n",
    "\\frac{\\partial N}{\\partial u_1} = \\frac{-1-t}{u_1 - d_1} + \\frac{1}{12 - 2u_2 - u_1} + \\frac{2}{12 - 2u_1 - u_2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial N}{\\partial u_2} = \\frac{-1-t}{u_2 - d_2} + \\frac{2}{12 - 2u_2 - u_1} + \\frac{1}{12 - 2u_1 - u_2}\n",
    "$$\n",
    "\n",
    "- Thus the gradient of f(x,y) is a vector of the form:\n",
    "\n",
    "$$\n",
    "\\nabla N = \\begin{vmatrix} \n",
    "\\frac{\\partial N}{\\partial u_1} \\\\\n",
    "\\\\\n",
    "\\frac{\\partial N}{\\partial u_2}\n",
    "\\end{vmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the gradient of the objective function\n",
    "def grad_Nash(u, t):\n",
    "    u1 = u[0]\n",
    "    u2 = u[1]\n",
    "    try:\n",
    "        dg_du1 = ((-1-t)/(u1-d1)) + (1/(12-2*u2-u1)) + (2/(12-2*u1-u2))\n",
    "        dg_du2 = ((-1-t)/(u2-d2)) + (2/(12-2*u2-u1)) + (1/(12-2*u1-u2))\n",
    "    except:\n",
    "        dg_du1 = 1e-20\n",
    "        dg_du2 = 1e-20\n",
    "    \n",
    "    return np.array([dg_du1, dg_du2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the Hessian Matrix, we need the double partial derivates with respect to u_1 and u_2. Calculated them as follows:\n",
    "$$ \n",
    "\\frac{\\partial^{2} N}{\\partial u_{1}^2} = \\frac{1+t}{(u_1 - d_1)^{2}} - \\frac{1}{(12 - 2u_2 - u_1)^2} - \\frac{4}{(12 - 2u_1 - u_2)^2} \n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial^{2} N}{\\partial u_{1}u_{2}} = \\frac{\\partial^{2} N}{\\partial u_{2}u_{1}} = \\frac{-2}{(12 - 2u_2 - u_1)^2} - \\frac{2}{(12 - 2u_1 - u_2)^2} \n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial^{2} N}{\\partial u_{2}^2} = \\frac{1+t}{(u_2 - d_2)^{2}} - \\frac{4}{(12 - 2u_2 - u_1)^2} - \\frac{1}{(12 - 2u_1 - u_2)^2} \n",
    "$$\n",
    "\n",
    "- Thus the Hessian Matrix of the given function $N(u_1, u_2)$ at any $(u_1, u_2)$ will be:\n",
    "$$\n",
    "H(x,y) = \\begin{vmatrix} \n",
    "\\frac{\\partial^{2} N}{\\partial u_{1}^2}    \\frac{\\partial^{2} N}{\\partial u_{1}u_{2}} \\\\\n",
    "\\\\\n",
    "\\frac{\\partial^{2} N}{\\partial u_{2}u_{1}}     \\frac{\\partial^{2} N}{\\partial u_{2}^2} \n",
    "\\end{vmatrix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the Hessian of the objective function\n",
    "def hess_Nash(u1, u2, t):\n",
    "    try:\n",
    "        d2g_d2u1 = (-1/(12-2*u2-u1)**2) - (4/(12-2*u1-u2)**2) + ((t+1)/((u1-d1)**2))\n",
    "        d2g_d2u2 = (-4/(12-2*u2-u1)**2) - (1/(12-2*u1-u2)**2) + ((t+1)/((u2-d2)**2))\n",
    "        d2g_du1_du2 = -2/(12-2*u2-u1)**2 - 2/(12-2*u1-u2)**2\n",
    "    except:\n",
    "        d2g_d2u1 = 1e-20\n",
    "        d2g_d2u2 = 1e-20\n",
    "        d2g_du1_du2 = 1e-20\n",
    "    \n",
    "    return np.array([[d2g_d2u1, d2g_du1_du2], [d2g_du1_du2, d2g_d2u2]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We implement the Backtracking Line Search for finding the step-size of the Newton Descent with constants as follows:\n",
    "$$\n",
    "\\alpha = 0.1 \\\\\n",
    "\\beta = 0.3 \\\\\n",
    "\\epsilon = 10^{-5} \\space (tolerance)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Backtracking Line Search\n",
    "def linear_search(d, alpha, beta, point, t):\n",
    "    x = point[0]\n",
    "    y = point[1]\n",
    "    step_size = 1\n",
    "    grad = grad_Nash(x, y, t)\n",
    "    while (Nash(x + step_size*d[0], y + step_size*d[1], t) > Nash(x, y, t) + alpha*beta*step_size*np.dot(grad, d)):\n",
    "        step_size *= beta\n",
    "    return step_size\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We define the Newton Descent Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a matrix is positive definite\n",
    "def is_pos_def(x):\n",
    "\n",
    "    # For checking if a matrix is positive definite we check if all the eigenvalues are positive (applicable for symmetric matrices)\n",
    "    return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "# Implementing the Newton Descent Method\n",
    "def newton_descent(x0, y0, t, alpha, beta, epsilon, max_iters):\n",
    "    # Initialize the variables\n",
    "    x = x0\n",
    "    y = y0\n",
    "\n",
    "    #Initializing the loop\n",
    "    while (np.linalg.norm(grad_Nash(x, y, t)) > epsilon) and (max_iters != 0):\n",
    "        \n",
    "        # Compute the gradient\n",
    "        grad = grad_Nash(x, y, t)\n",
    "\n",
    "        # Compute the Hessian\n",
    "        hess = hess_Nash(x, y, t)\n",
    "            \n",
    "        # Combination Descent Condition:\n",
    "        if(is_pos_def(hess)):\n",
    "\n",
    "            # If the Hessian is positive definite, we use the Newton Step\n",
    "            \n",
    "            # Computing the inverse of the Hessian\n",
    "            hess_inverse = np.linalg.inv(hess)\n",
    "\n",
    "            # Computing the Newton Step by taking the negative of the Hessian inverse dotted with the gradient vector\n",
    "            d = -np.dot(hess_inverse, grad)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # If the Hessian is not positive definite, we use the Gradient Descent Step which is the negative of the gradient vector\n",
    "            d = -grad\n",
    "        \n",
    "        # Compute the step size\n",
    "        step_size = linear_search(d, alpha, beta, [x,y], t)\n",
    "\n",
    "        # Update the variables\n",
    "        x = x + step_size*d[0]\n",
    "        y = y + step_size*d[1]\n",
    "\n",
    "        # Update the number of iterations\n",
    "        max_iters = max_iters - 1\n",
    "\n",
    "    # Return the solution as a numpy array with the number of iterations it took and the coordinates of the solution point\n",
    "    return np.array([x, y, max_iters])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of Interior Point Algorithm\n",
    "- Here we implement the Interior Point Algorithm from scratch.\n",
    "- We pass the initial guess for the primal point as an array:\n",
    "$$\n",
    "u = (u_1, u_2) = (3, 3)\n",
    "$$\n",
    "- We initially choose the following constants:\n",
    "$$\n",
    "t = 1 \\\\\n",
    "\\mu = 15\n",
    "$$\n",
    "\n",
    "- We iterate as we try to solve the minimisation problem with our given initial point and updating $u_1$ and $u_2$ accordingly.\n",
    "\n",
    "- We update the value of $t$ and keep on incrementing till we achieve the KKT optimality conditions which is:\n",
    "$$\n",
    "\\frac{m}{t} < \\epsilon\n",
    "$$\n",
    "- where $\\epsilon$ is the tolerance ($10^{-5}$) and $m$ is the number of inequality constraints i.e. $4$ here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We return the final values of $u_1$, $u_2$ and $t$ from this algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interior Point Algorithm Implementation\n",
    "def interior_point(u, t, mu, max_iter, tol, m):\n",
    "\n",
    "    # Initialize the primal points\n",
    "    u1 = u[0]\n",
    "    u2 = u[1]\n",
    "\n",
    "    # Iterate until the maximum number of iterations is reached\n",
    "    while(max_iter != 0):\n",
    "\n",
    "        # Check if the accuracy is good enough\n",
    "        if(m / t < tol):\n",
    "            break\n",
    "        \n",
    "        # Prepare the initial guess for the primal points\n",
    "        u = np.array([u1, u2])\n",
    "\n",
    "        # Compute new primal point using Newton Descent Method\n",
    "        #ress = newton_descent(u1, u2, t, 0.1, 0.3, tol, 1000)\n",
    "\n",
    "        res = minimize(Nash, u, args = (t,), method='SLSQP', \n",
    "                                constraints=[{'type': 'ineq', 'fun': constraint1},\n",
    "                                            {'type': 'ineq', 'fun': constraint2},\n",
    "                                            {'type': 'ineq', 'fun': constraint3},\n",
    "                                            {'type': 'ineq', 'fun': constraint4}])\n",
    "\n",
    "        # Update the primal points\n",
    "        primal_point = res.x\n",
    "        u1 = primal_point[0]\n",
    "        u2 = primal_point[1]\n",
    "        \n",
    "        # We increase accuracy\n",
    "        t = t*(1 + (1.0)/(10*np.sqrt(mu)))\n",
    "\n",
    "        # Update the number of iterations\n",
    "        max_iter = max_iter - 1\n",
    "    \n",
    "    # Return the solution as a numpy array with the final value of t and the coordinates of the solution point\n",
    "    return np.array([u1, u2, t])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we define the constants and call the interior point algorithm on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c9/s8062nf53sv0b6gfv3ct0lv80000gn/T/ipykernel_83708/3826924504.py:8: RuntimeWarning: divide by zero encountered in log\n",
      "  return -(np.log((12-2*u2-u1)*(12-2*u1-u2)*(u1-d1)*(u2-d2))/t) - np.log((u1-d1)*(u2-d2))\n",
      "/var/folders/c9/s8062nf53sv0b6gfv3ct0lv80000gn/T/ipykernel_83708/3826924504.py:8: RuntimeWarning: invalid value encountered in log\n",
      "  return -(np.log((12-2*u2-u1)*(12-2*u1-u2)*(u1-d1)*(u2-d2))/t) - np.log((u1-d1)*(u2-d2))\n"
     ]
    }
   ],
   "source": [
    "# Initial constants\n",
    "\n",
    "# Maximum number of iterations\n",
    "max_iter = 1000\n",
    "\n",
    "# Tolerance\n",
    "tol = 1e-5\n",
    "\n",
    "# Initial value of t\n",
    "t_init = 1 \n",
    "\n",
    "# Number of constraints\n",
    "m = 4 \n",
    "\n",
    "# Initial values of the primal points\n",
    "u1 = 3\n",
    "u2 = 3\n",
    "u = np.array([u1, u2])\n",
    "\n",
    "# Accuracy multiplier\n",
    "mu = 10 \n",
    "\n",
    "# Call the interior point algorithm\n",
    "solution = interior_point(u, t_init, mu, max_iter, tol, m)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we print the initial and final value of $t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial value of t:  1\n",
      "Final value of t:  408491.17153674125\n"
     ]
    }
   ],
   "source": [
    "# Extract the solution\n",
    "u1 = solution[0]\n",
    "u2 = solution[1]\n",
    "t_final = solution[2]\n",
    "\n",
    "# Initial and Final value of t\n",
    "print(\"Initial value of t: \", t_init)\n",
    "print(\"Final value of t: \", t_final)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we print the final bargaining solution for the problem $(u_1, u_2)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bargaining solution is: \n",
      "u1 =  4.000007900982537\n",
      "u2 =  3.9999722225484375\n"
     ]
    }
   ],
   "source": [
    "# Print the solution\n",
    "print(\"The bargaining solution is: \")\n",
    "print(\"u1 = \", u1)\n",
    "print(\"u2 = \", u2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The solution for this problem thus is approximately:\n",
    "$$\n",
    "(u_1, u_2) = (4, 4)\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We put these values in the Nash Welfare Criterion:\n",
    "$$\n",
    "\\log(u_1 - d_1) + \\log(u_2 - d_2)\n",
    "$$\n",
    "- to get the Maximised Nash Welfare or the Primal Optimal Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Maximised Nash Welfare (Primal Optimal Value) is: \n",
      "1.791754160518133\n"
     ]
    }
   ],
   "source": [
    "# The Nash Welfare Criterion\n",
    "print(\"The Maximised Nash Welfare (Primal Optimal Value) is: \")\n",
    "print(log(u1 - d1) + log(u2 - d2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thus the maximised Nash Welfare is approximately equal to $1.79$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we print the inequality constraint function values at the optimum $(u_1, u_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constraint 1: 2u1 + u2 <= 12\n",
      "Constraint 2: u1 + 2u2 <= 12\n",
      "Constraint 3: u1 >= d1\n",
      "Constraint 4: u2 >= d2\n",
      "\n",
      "The constraint values are: \n",
      "Constraint 1:  4.765392058825313e-05\n",
      "Constraint 2:  1.1975486489124165e-05\n",
      "Constraint 3:  2.0000079009825367\n",
      "Constraint 4:  2.9999722225484375\n"
     ]
    }
   ],
   "source": [
    "print(\"Constraint 1: 2u1 + u2 <= 12\")\n",
    "print(\"Constraint 2: u1 + 2u2 <= 12\")\n",
    "print(\"Constraint 3: u1 >= d1\")\n",
    "print(\"Constraint 4: u2 >= d2\")\n",
    "\n",
    "print()\n",
    "# Printing the constraint values\n",
    "print(\"The constraint values are: \")\n",
    "print(\"Constraint 1: \", constraint1((u1, u2)))\n",
    "print(\"Constraint 2: \", constraint2((u1, u2)))\n",
    "print(\"Constraint 3: \", constraint3((u1, u2)))\n",
    "print(\"Constraint 4: \", constraint4((u1, u2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dual optimum variables corresponding to each constraint is given by:\n",
    "$$\n",
    "\\lambda_{i} = \\frac{-1}{t*f_{i}{(x)}}\n",
    "$$\n",
    "\n",
    "- where $f_{i}{(x)}$ refers to the $i^{th}$ inequality constraint as defined above also.\n",
    "- and $t$ refers to final value of $t$ from the Interior Point Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dual optimums are: \n",
      "lambda1 =  0.05137107907600213\n",
      "lambda2 =  0.2044203653057368\n",
      "lambda3 =  1.2240118259623078e-06\n",
      "lambda4 =  8.160186632465232e-07\n"
     ]
    }
   ],
   "source": [
    "# Computing the dual optimums corresponding to each constraint\n",
    "lambda1 = (1)/(t_final*constraint1((u1, u2)))\n",
    "lambda2 = (1)/(t_final*constraint2((u1, u2)))\n",
    "lambda3 = (1)/(t_final*constraint3((u1, u2)))\n",
    "lambda4 = (1)/(t_final*constraint4((u1, u2)))\n",
    "\n",
    "# Printing the dual optimums\n",
    "print(\"The dual optimums are: \")\n",
    "print(\"lambda1 = \", lambda1)\n",
    "print(\"lambda2 = \", lambda2)\n",
    "print(\"lambda3 = \", lambda3)\n",
    "print(\"lambda4 = \", lambda4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
